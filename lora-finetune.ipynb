{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport torch\ndevice ='cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-24T15:41:33.512133Z","iopub.execute_input":"2024-10-24T15:41:33.512977Z","iopub.status.idle":"2024-10-24T15:41:37.195577Z","shell.execute_reply.started":"2024-10-24T15:41:33.512930Z","shell.execute_reply":"2024-10-24T15:41:37.194445Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install transformers accelerate torch huggingface_hub peft","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:41:40.650414Z","iopub.execute_input":"2024-10-24T15:41:40.651185Z","iopub.status.idle":"2024-10-24T15:41:53.679984Z","shell.execute_reply.started":"2024-10-24T15:41:40.651145Z","shell.execute_reply":"2024-10-24T15:41:53.678928Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\nCollecting peft\n  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: peft\nSuccessfully installed peft-0.13.2\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(\"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\")","metadata":{"execution":{"iopub.status.busy":"2024-10-24T15:42:02.082598Z","iopub.execute_input":"2024-10-24T15:42:02.083355Z","iopub.status.idle":"2024-10-24T15:42:02.655562Z","shell.execute_reply.started":"2024-10-24T15:42:02.083311Z","shell.execute_reply":"2024-10-24T15:42:02.654631Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\nmodel_name = \"openai-community/gpt2-medium\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntokenizer.pad_token = tokenizer.eos_token\n\nmodel = AutoModelForCausalLM.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:00:03.155808Z","iopub.execute_input":"2024-10-24T18:00:03.156554Z","iopub.status.idle":"2024-10-24T18:00:10.297097Z","shell.execute_reply.started":"2024-10-24T18:00:03.156511Z","shell.execute_reply":"2024-10-24T18:00:10.296198Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8402e4eb4834239990ab20a5346004f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/718 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c15f4117a6cd43ab80dda9c97dc63919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"164020ed2e5340b291932cef6ae95d4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a200dca72da47ca86dc9cdec8b32888"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc8fa6e36701435bab2ee22a7ef1063d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.52G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e82a0e422d8a43d4834163e26f5bb117"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a104b4a4f67649ed9a7eb2f99e545525"}},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset\n\ndata = load_dataset(\"openai/gsm8k\", \"main\")\ndata","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:00:19.157711Z","iopub.execute_input":"2024-10-24T18:00:19.158129Z","iopub.status.idle":"2024-10-24T18:00:20.990747Z","shell.execute_reply.started":"2024-10-24T18:00:19.158092Z","shell.execute_reply":"2024-10-24T18:00:20.989836Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['question', 'answer'],\n        num_rows: 7473\n    })\n    test: Dataset({\n        features: ['question', 'answer'],\n        num_rows: 1319\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def print_number_of_trainable_model_parameters(model):\n    trainable_model_params = 0\n    all_model_params = 0\n    for _, param in model.named_parameters():\n        all_model_params += param.numel()\n        if param.requires_grad:\n            trainable_model_params += param.numel()\n    return (f\"Trainable model parameters: {trainable_model_params}, All model parameters: {all_model_params},percentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\")\n\n\nprint(print_number_of_trainable_model_parameters(model))","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:00:24.986844Z","iopub.execute_input":"2024-10-24T18:00:24.987230Z","iopub.status.idle":"2024-10-24T18:00:24.997398Z","shell.execute_reply.started":"2024-10-24T18:00:24.987193Z","shell.execute_reply":"2024-10-24T18:00:24.996518Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Trainable model parameters: 354823168, All model parameters: 354823168,percentage of trainable model parameters: 100.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model, TaskType\n\nlora_config = LoraConfig(r=32,lora_alpha = 64, target_modules=[\"attn.c_attn\", \"attn.q_proj\", \"attn.v_proj\"],\n                         lora_dropout = 0.2, bias =\"none\")\npeft_model_train = get_peft_model(model, lora_config)\nprint_number_of_trainable_model_parameters(peft_model_train)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:01:48.401194Z","iopub.execute_input":"2024-10-24T18:01:48.401966Z","iopub.status.idle":"2024-10-24T18:01:48.482520Z","shell.execute_reply.started":"2024-10-24T18:01:48.401927Z","shell.execute_reply":"2024-10-24T18:01:48.481588Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1150: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'Trainable model parameters: 3145728, All model parameters: 357968896,percentage of trainable model parameters: 0.88%'"},"metadata":{}}]},{"cell_type":"code","source":"for name, module in model.named_modules():\n    print(name)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:00:36.240743Z","iopub.execute_input":"2024-10-24T18:00:36.241138Z","iopub.status.idle":"2024-10-24T18:00:36.310494Z","shell.execute_reply.started":"2024-10-24T18:00:36.241104Z","shell.execute_reply":"2024-10-24T18:00:36.309567Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\ntransformer\ntransformer.wte\ntransformer.wpe\ntransformer.drop\ntransformer.h\ntransformer.h.0\ntransformer.h.0.ln_1\ntransformer.h.0.attn\ntransformer.h.0.attn.c_attn\ntransformer.h.0.attn.c_proj\ntransformer.h.0.attn.attn_dropout\ntransformer.h.0.attn.resid_dropout\ntransformer.h.0.ln_2\ntransformer.h.0.mlp\ntransformer.h.0.mlp.c_fc\ntransformer.h.0.mlp.c_proj\ntransformer.h.0.mlp.act\ntransformer.h.0.mlp.dropout\ntransformer.h.1\ntransformer.h.1.ln_1\ntransformer.h.1.attn\ntransformer.h.1.attn.c_attn\ntransformer.h.1.attn.c_proj\ntransformer.h.1.attn.attn_dropout\ntransformer.h.1.attn.resid_dropout\ntransformer.h.1.ln_2\ntransformer.h.1.mlp\ntransformer.h.1.mlp.c_fc\ntransformer.h.1.mlp.c_proj\ntransformer.h.1.mlp.act\ntransformer.h.1.mlp.dropout\ntransformer.h.2\ntransformer.h.2.ln_1\ntransformer.h.2.attn\ntransformer.h.2.attn.c_attn\ntransformer.h.2.attn.c_proj\ntransformer.h.2.attn.attn_dropout\ntransformer.h.2.attn.resid_dropout\ntransformer.h.2.ln_2\ntransformer.h.2.mlp\ntransformer.h.2.mlp.c_fc\ntransformer.h.2.mlp.c_proj\ntransformer.h.2.mlp.act\ntransformer.h.2.mlp.dropout\ntransformer.h.3\ntransformer.h.3.ln_1\ntransformer.h.3.attn\ntransformer.h.3.attn.c_attn\ntransformer.h.3.attn.c_proj\ntransformer.h.3.attn.attn_dropout\ntransformer.h.3.attn.resid_dropout\ntransformer.h.3.ln_2\ntransformer.h.3.mlp\ntransformer.h.3.mlp.c_fc\ntransformer.h.3.mlp.c_proj\ntransformer.h.3.mlp.act\ntransformer.h.3.mlp.dropout\ntransformer.h.4\ntransformer.h.4.ln_1\ntransformer.h.4.attn\ntransformer.h.4.attn.c_attn\ntransformer.h.4.attn.c_proj\ntransformer.h.4.attn.attn_dropout\ntransformer.h.4.attn.resid_dropout\ntransformer.h.4.ln_2\ntransformer.h.4.mlp\ntransformer.h.4.mlp.c_fc\ntransformer.h.4.mlp.c_proj\ntransformer.h.4.mlp.act\ntransformer.h.4.mlp.dropout\ntransformer.h.5\ntransformer.h.5.ln_1\ntransformer.h.5.attn\ntransformer.h.5.attn.c_attn\ntransformer.h.5.attn.c_proj\ntransformer.h.5.attn.attn_dropout\ntransformer.h.5.attn.resid_dropout\ntransformer.h.5.ln_2\ntransformer.h.5.mlp\ntransformer.h.5.mlp.c_fc\ntransformer.h.5.mlp.c_proj\ntransformer.h.5.mlp.act\ntransformer.h.5.mlp.dropout\ntransformer.h.6\ntransformer.h.6.ln_1\ntransformer.h.6.attn\ntransformer.h.6.attn.c_attn\ntransformer.h.6.attn.c_proj\ntransformer.h.6.attn.attn_dropout\ntransformer.h.6.attn.resid_dropout\ntransformer.h.6.ln_2\ntransformer.h.6.mlp\ntransformer.h.6.mlp.c_fc\ntransformer.h.6.mlp.c_proj\ntransformer.h.6.mlp.act\ntransformer.h.6.mlp.dropout\ntransformer.h.7\ntransformer.h.7.ln_1\ntransformer.h.7.attn\ntransformer.h.7.attn.c_attn\ntransformer.h.7.attn.c_proj\ntransformer.h.7.attn.attn_dropout\ntransformer.h.7.attn.resid_dropout\ntransformer.h.7.ln_2\ntransformer.h.7.mlp\ntransformer.h.7.mlp.c_fc\ntransformer.h.7.mlp.c_proj\ntransformer.h.7.mlp.act\ntransformer.h.7.mlp.dropout\ntransformer.h.8\ntransformer.h.8.ln_1\ntransformer.h.8.attn\ntransformer.h.8.attn.c_attn\ntransformer.h.8.attn.c_proj\ntransformer.h.8.attn.attn_dropout\ntransformer.h.8.attn.resid_dropout\ntransformer.h.8.ln_2\ntransformer.h.8.mlp\ntransformer.h.8.mlp.c_fc\ntransformer.h.8.mlp.c_proj\ntransformer.h.8.mlp.act\ntransformer.h.8.mlp.dropout\ntransformer.h.9\ntransformer.h.9.ln_1\ntransformer.h.9.attn\ntransformer.h.9.attn.c_attn\ntransformer.h.9.attn.c_proj\ntransformer.h.9.attn.attn_dropout\ntransformer.h.9.attn.resid_dropout\ntransformer.h.9.ln_2\ntransformer.h.9.mlp\ntransformer.h.9.mlp.c_fc\ntransformer.h.9.mlp.c_proj\ntransformer.h.9.mlp.act\ntransformer.h.9.mlp.dropout\ntransformer.h.10\ntransformer.h.10.ln_1\ntransformer.h.10.attn\ntransformer.h.10.attn.c_attn\ntransformer.h.10.attn.c_proj\ntransformer.h.10.attn.attn_dropout\ntransformer.h.10.attn.resid_dropout\ntransformer.h.10.ln_2\ntransformer.h.10.mlp\ntransformer.h.10.mlp.c_fc\ntransformer.h.10.mlp.c_proj\ntransformer.h.10.mlp.act\ntransformer.h.10.mlp.dropout\ntransformer.h.11\ntransformer.h.11.ln_1\ntransformer.h.11.attn\ntransformer.h.11.attn.c_attn\ntransformer.h.11.attn.c_proj\ntransformer.h.11.attn.attn_dropout\ntransformer.h.11.attn.resid_dropout\ntransformer.h.11.ln_2\ntransformer.h.11.mlp\ntransformer.h.11.mlp.c_fc\ntransformer.h.11.mlp.c_proj\ntransformer.h.11.mlp.act\ntransformer.h.11.mlp.dropout\ntransformer.h.12\ntransformer.h.12.ln_1\ntransformer.h.12.attn\ntransformer.h.12.attn.c_attn\ntransformer.h.12.attn.c_proj\ntransformer.h.12.attn.attn_dropout\ntransformer.h.12.attn.resid_dropout\ntransformer.h.12.ln_2\ntransformer.h.12.mlp\ntransformer.h.12.mlp.c_fc\ntransformer.h.12.mlp.c_proj\ntransformer.h.12.mlp.act\ntransformer.h.12.mlp.dropout\ntransformer.h.13\ntransformer.h.13.ln_1\ntransformer.h.13.attn\ntransformer.h.13.attn.c_attn\ntransformer.h.13.attn.c_proj\ntransformer.h.13.attn.attn_dropout\ntransformer.h.13.attn.resid_dropout\ntransformer.h.13.ln_2\ntransformer.h.13.mlp\ntransformer.h.13.mlp.c_fc\ntransformer.h.13.mlp.c_proj\ntransformer.h.13.mlp.act\ntransformer.h.13.mlp.dropout\ntransformer.h.14\ntransformer.h.14.ln_1\ntransformer.h.14.attn\ntransformer.h.14.attn.c_attn\ntransformer.h.14.attn.c_proj\ntransformer.h.14.attn.attn_dropout\ntransformer.h.14.attn.resid_dropout\ntransformer.h.14.ln_2\ntransformer.h.14.mlp\ntransformer.h.14.mlp.c_fc\ntransformer.h.14.mlp.c_proj\ntransformer.h.14.mlp.act\ntransformer.h.14.mlp.dropout\ntransformer.h.15\ntransformer.h.15.ln_1\ntransformer.h.15.attn\ntransformer.h.15.attn.c_attn\ntransformer.h.15.attn.c_proj\ntransformer.h.15.attn.attn_dropout\ntransformer.h.15.attn.resid_dropout\ntransformer.h.15.ln_2\ntransformer.h.15.mlp\ntransformer.h.15.mlp.c_fc\ntransformer.h.15.mlp.c_proj\ntransformer.h.15.mlp.act\ntransformer.h.15.mlp.dropout\ntransformer.h.16\ntransformer.h.16.ln_1\ntransformer.h.16.attn\ntransformer.h.16.attn.c_attn\ntransformer.h.16.attn.c_proj\ntransformer.h.16.attn.attn_dropout\ntransformer.h.16.attn.resid_dropout\ntransformer.h.16.ln_2\ntransformer.h.16.mlp\ntransformer.h.16.mlp.c_fc\ntransformer.h.16.mlp.c_proj\ntransformer.h.16.mlp.act\ntransformer.h.16.mlp.dropout\ntransformer.h.17\ntransformer.h.17.ln_1\ntransformer.h.17.attn\ntransformer.h.17.attn.c_attn\ntransformer.h.17.attn.c_proj\ntransformer.h.17.attn.attn_dropout\ntransformer.h.17.attn.resid_dropout\ntransformer.h.17.ln_2\ntransformer.h.17.mlp\ntransformer.h.17.mlp.c_fc\ntransformer.h.17.mlp.c_proj\ntransformer.h.17.mlp.act\ntransformer.h.17.mlp.dropout\ntransformer.h.18\ntransformer.h.18.ln_1\ntransformer.h.18.attn\ntransformer.h.18.attn.c_attn\ntransformer.h.18.attn.c_proj\ntransformer.h.18.attn.attn_dropout\ntransformer.h.18.attn.resid_dropout\ntransformer.h.18.ln_2\ntransformer.h.18.mlp\ntransformer.h.18.mlp.c_fc\ntransformer.h.18.mlp.c_proj\ntransformer.h.18.mlp.act\ntransformer.h.18.mlp.dropout\ntransformer.h.19\ntransformer.h.19.ln_1\ntransformer.h.19.attn\ntransformer.h.19.attn.c_attn\ntransformer.h.19.attn.c_proj\ntransformer.h.19.attn.attn_dropout\ntransformer.h.19.attn.resid_dropout\ntransformer.h.19.ln_2\ntransformer.h.19.mlp\ntransformer.h.19.mlp.c_fc\ntransformer.h.19.mlp.c_proj\ntransformer.h.19.mlp.act\ntransformer.h.19.mlp.dropout\ntransformer.h.20\ntransformer.h.20.ln_1\ntransformer.h.20.attn\ntransformer.h.20.attn.c_attn\ntransformer.h.20.attn.c_proj\ntransformer.h.20.attn.attn_dropout\ntransformer.h.20.attn.resid_dropout\ntransformer.h.20.ln_2\ntransformer.h.20.mlp\ntransformer.h.20.mlp.c_fc\ntransformer.h.20.mlp.c_proj\ntransformer.h.20.mlp.act\ntransformer.h.20.mlp.dropout\ntransformer.h.21\ntransformer.h.21.ln_1\ntransformer.h.21.attn\ntransformer.h.21.attn.c_attn\ntransformer.h.21.attn.c_proj\ntransformer.h.21.attn.attn_dropout\ntransformer.h.21.attn.resid_dropout\ntransformer.h.21.ln_2\ntransformer.h.21.mlp\ntransformer.h.21.mlp.c_fc\ntransformer.h.21.mlp.c_proj\ntransformer.h.21.mlp.act\ntransformer.h.21.mlp.dropout\ntransformer.h.22\ntransformer.h.22.ln_1\ntransformer.h.22.attn\ntransformer.h.22.attn.c_attn\ntransformer.h.22.attn.c_proj\ntransformer.h.22.attn.attn_dropout\ntransformer.h.22.attn.resid_dropout\ntransformer.h.22.ln_2\ntransformer.h.22.mlp\ntransformer.h.22.mlp.c_fc\ntransformer.h.22.mlp.c_proj\ntransformer.h.22.mlp.act\ntransformer.h.22.mlp.dropout\ntransformer.h.23\ntransformer.h.23.ln_1\ntransformer.h.23.attn\ntransformer.h.23.attn.c_attn\ntransformer.h.23.attn.c_proj\ntransformer.h.23.attn.attn_dropout\ntransformer.h.23.attn.resid_dropout\ntransformer.h.23.ln_2\ntransformer.h.23.mlp\ntransformer.h.23.mlp.c_fc\ntransformer.h.23.mlp.c_proj\ntransformer.h.23.mlp.act\ntransformer.h.23.mlp.dropout\ntransformer.ln_f\nlm_head\n","output_type":"stream"}]},{"cell_type":"code","source":"def preprocess_function(examples):\n    inputs = [q + \" \" + a for q, a in zip(examples['question'], examples['answer'])]\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    model_inputs[\"labels\"] = model_inputs[\"input_ids\"].copy()\n    \n    return model_inputs\ntokenized_datasets = data.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:01:56.981331Z","iopub.execute_input":"2024-10-24T18:01:56.982077Z","iopub.status.idle":"2024-10-24T18:02:01.629746Z","shell.execute_reply.started":"2024-10-24T18:01:56.982038Z","shell.execute_reply":"2024-10-24T18:02:01.628841Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7473 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3a06adf18474351992f6646f2633fdc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1319 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d392373e3424351a5b003189060fedd"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir=\"/kaggle/working/results\",\n    num_train_epochs=2,\n    per_device_train_batch_size=2,\n    per_device_eval_batch_size=2,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"/kaggle/working/logs\",\n)\n\ntrainer = Trainer(\n    model=peft_model_train,\n    args=training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"test\"],\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:02:12.885582Z","iopub.execute_input":"2024-10-24T18:02:12.886428Z","iopub.status.idle":"2024-10-24T18:49:58.865040Z","shell.execute_reply.started":"2024-10-24T18:02:12.886389Z","shell.execute_reply":"2024-10-24T18:49:58.864153Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7474' max='7474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7474/7474 47:44, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>3.466600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.614500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.559500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.550200</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.525400</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.521100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.522000</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.515800</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.520700</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.493900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.495900</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.499000</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.498800</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.494000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7474, training_loss=0.7196396788652485, metrics={'train_runtime': 2864.7647, 'train_samples_per_second': 5.217, 'train_steps_per_second': 2.609, 'total_flos': 1.4024793888129024e+16, 'train_loss': 0.7196396788652485, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"import zipfile\nimport os\n\ndef zip_dir(directory_path, zip_name):\n    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        for root, dirs, files in os.walk(directory_path):\n            for file in files:\n                file_path = os.path.join(root, file)\n                arcname = os.path.relpath(file_path, directory_path)\n                zipf.write(file_path, arcname)\nzip_dir('/kaggle/working/results', '/kaggle/working/results_archive2.zip')\nzip_dir('/kaggle/working/logs', '/kaggle/working/logs_archive2.zip')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:56:59.589717Z","iopub.execute_input":"2024-10-24T18:56:59.590389Z","iopub.status.idle":"2024-10-24T18:57:30.719005Z","shell.execute_reply.started":"2024-10-24T18:56:59.590346Z","shell.execute_reply":"2024-10-24T18:57:30.717982Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"peft_model_path=\"/kaggle/working/pretrained2\"\n\ntrainer.model.save_pretrained(peft_model_path)\ntokenizer.save_pretrained(peft_model_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T18:58:30.378468Z","iopub.execute_input":"2024-10-24T18:58:30.378883Z","iopub.status.idle":"2024-10-24T18:58:30.730953Z","shell.execute_reply.started":"2024-10-24T18:58:30.378844Z","shell.execute_reply":"2024-10-24T18:58:30.729999Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/pretrained2/tokenizer_config.json',\n '/kaggle/working/pretrained2/special_tokens_map.json',\n '/kaggle/working/pretrained2/vocab.json',\n '/kaggle/working/pretrained2/merges.txt',\n '/kaggle/working/pretrained2/added_tokens.json',\n '/kaggle/working/pretrained2/tokenizer.json')"},"metadata":{}}]},{"cell_type":"code","source":"zip_dir('/kaggle/working/pretrained2', '/kaggle/working/pretrained_archive2.zip')","metadata":{"execution":{"iopub.status.busy":"2024-10-24T19:01:12.280874Z","iopub.execute_input":"2024-10-24T19:01:12.281261Z","iopub.status.idle":"2024-10-24T19:01:13.223858Z","shell.execute_reply.started":"2024-10-24T19:01:12.281224Z","shell.execute_reply":"2024-10-24T19:01:13.222832Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}